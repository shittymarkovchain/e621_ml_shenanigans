{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKirMSQUkwna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MsuS0XqM7Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGcVG_KRkz5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jiyCWpki40r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    from apex import amp\n",
        "except:\n",
        "    ! git clone https://github.com/NVIDIA/apex\n",
        "    ! cd apex && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
        "    from apex import amp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ91CH-Ik2QK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = '/content/gdrive/My Drive/ML/stuff'\n",
        "DATA = f'{ROOT}/data'\n",
        "OUT = f'{ROOT}/out'\n",
        "\n",
        "if not Path(OUT).exists():\n",
        "    ! mkdir \"$OUT\"\n",
        "    ! mkdir \"$OUT/images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjFVyrblk_so",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(f\"{DATA}/data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXk_va0clE9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\", \"author\", \"file_url\", \"sample_url\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udltZzz7lFXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"tags\"] = df[\"tags\"].apply(lambda x: set(x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFP4xMPDpXJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_tags = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwNq_ARJlgAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_count = defaultdict(lambda: 0)\n",
        "for tags in df[\"tags\"]:\n",
        "    for t in tags:\n",
        "        tags_count[t] += 1\n",
        "to_sort = []\n",
        "for t in tags_count:\n",
        "    to_sort.append((tags_count[t], t))\n",
        "to_sort.sort()\n",
        "to_sort = to_sort[::-1]\n",
        "common_tags = [x[1] for x in to_sort[:n_tags]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thpJBDKJmlNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eeov5TrBuT7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omZO5EJGuT51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ29n7PvuT15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X8brpR6m8ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upvoted = df[df[\"score\"] > 90]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLJfzWfDtZeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df\n",
        "del to_sort\n",
        "del tags_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeQy34SDw4xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upvoted = upvoted.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT3K2WTbqb0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensors = dict()\n",
        "for v in upvoted:\n",
        "    fav, id, rating, score, tags = v\n",
        "    res = [1 if t in tags else 0 for t in common_tags]\n",
        "    res += [1 if r == rating else 0 for r in ['s', 'q', 'e']]\n",
        "    res += [score, fav]\n",
        "    tensors[id] = torch.Tensor(res)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcz5CCXnmoba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del upvoted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kOvFRoYz_VQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users = pickle.load(open(f\"{DATA}/users.p\", \"rb\"))\n",
        "delete = set()\n",
        "for u in users:\n",
        "    if len(users[u]) < 64:\n",
        "        delete.add(u)\n",
        "for u in delete:\n",
        "    del users[u]\n",
        "del delete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV0xwKjtE5NG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_all(model, opti, n_batch):\n",
        "    tmp_path = \"/tmp/all_train_data\"\n",
        "    data = [model.state_dict(), opti.state_dict(), n_batch]\n",
        "    out_path_2 = f\"{OUT}/train_{(n_batch // 5000) % 50}\"\n",
        "    torch.save(data, open(tmp_path, \"wb\"))\n",
        "    ! cp \"$tmp_path\" \"$OUT\"\n",
        "    ! cp \"$tmp_path\" \"$out_path_2\"\n",
        "def load_all(model, opti):\n",
        "    tmp_path = \"/tmp/all_train_data\"\n",
        "    ! cp \"$OUT/all_train_data\" \"$tmp_path\"\n",
        "    l = torch.load(open(tmp_path, \"rb\"))\n",
        "    model.load_state_dict(l[0])\n",
        "    opti.load_state_dict(l[1])\n",
        "    return [model, opti] + l[2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpfiyGrHkmue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMpsxyOontFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer(in_depth, k):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Conv1d(in_depth, k, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "        torch.nn.BatchNorm1d(k),\n",
        "        torch.nn.LeakyReLU(0.2)\n",
        "    )\n",
        "size_bottleneck = 32\n",
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        \n",
        "        self.conv = torch.nn.ModuleList([\n",
        "            layer(n_tags + 5, 256),\n",
        "            layer(256, 512),\n",
        "        ])\n",
        "        \n",
        "        self.features_extract = torch.nn.ModuleList([\n",
        "            torch.nn.Linear(512, 256),\n",
        "            torch.nn.LeakyReLU(0.2),\n",
        "            torch.nn.Linear(256, size_bottleneck),\n",
        "        ])\n",
        "        \n",
        "        self.is_fav = torch.nn.ModuleList([\n",
        "            layer(size_bottleneck + n_tags + 5, 256),\n",
        "            layer(256, 128),\n",
        "            torch.nn.Conv1d(128, 1, kernel_size=1, stride=1, padding=0),\n",
        "            torch.nn.Sigmoid()\n",
        "        ])\n",
        "    \n",
        "    def forward(self, favs, to_identify):\n",
        "        x = favs\n",
        "        for l in self.conv:\n",
        "            x = l(x)\n",
        "        x = x.mean(dim=2)\n",
        "        for l in self.features_extract:\n",
        "            x = l(x)\n",
        "        \n",
        "        fingerprint = x\n",
        "        \n",
        "        user_extended = x.view(-1, size_bottleneck, 1).repeat(1, 1, to_identify.shape[-1])\n",
        "        x = torch.cat([to_identify, user_extended], dim=1)\n",
        "        \n",
        "        for l in self.is_fav:\n",
        "            x = l(x)\n",
        "        return x.transpose(2, 1).reshape(x.shape[0], -1), fingerprint\n",
        "model = Network().to(device)\n",
        "\n",
        "\n",
        "\n",
        "lr = 0.00001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss = torch.nn.BCELoss()\n",
        "MP = False\n",
        "\n",
        "if MP:\n",
        "    model, optimizer = amp.initialize(\n",
        "       model, optimizer, opt_level=\"O2\", \n",
        "       keep_batchnorm_fp32=True, loss_scale=\"dynamic\"\n",
        "    )\n",
        "\n",
        "n_batch = 0\n",
        "#losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsbMnih-zzOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moQBirTN85di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, optimizer, n_batch = load_all(model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOjhHgZ7yl9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "ones = torch.ones(batch_size).to(device)\n",
        "model.train()\n",
        "for epoch in range(1000):\n",
        "    \n",
        "    users_shuffled = list(users)\n",
        "    random.shuffle(users_shuffled)\n",
        "    \n",
        "    for batch, begin in enumerate(range(0, len(users), batch_size)):\n",
        "        n_batch += 1\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        extract1 = []\n",
        "        extract2 = []\n",
        "        inputs_test1 = []\n",
        "        inputs_test2 = []\n",
        "        \n",
        "        n_samples = 32\n",
        "        n2_samples = n_samples * 2\n",
        "        \n",
        "        current_batch_size = min(begin + batch_size, len(users)) - begin\n",
        "        if current_batch_size != batch_size:\n",
        "            continue\n",
        "        \n",
        "        for i in range(begin, begin + current_batch_size):\n",
        "            u = users_shuffled[i]\n",
        "            favs = [tensors[i] for i in users[u]]\n",
        "            random.shuffle(favs)\n",
        "            \n",
        "            extract1.append(torch.stack(favs[:n_samples]))\n",
        "            extract2.append(torch.stack(favs[n_samples:n2_samples]))\n",
        "            \n",
        "            negatives = random.sample(list(tensors), n2_samples)\n",
        "            negatives1 = torch.stack([tensors[i] for i in negatives[:n_samples]])\n",
        "            negatives2 = torch.stack([tensors[i] for i in negatives[n_samples:]])\n",
        "            inputs_test1.append(torch.cat([extract1[-1], negatives1]))\n",
        "            inputs_test2.append(torch.cat([extract2[-1], negatives2]))\n",
        "\n",
        "            extract1[-1] = extract1[-1].transpose(1, 0).to(device)\n",
        "            extract2[-1] = extract2[-1].transpose(1, 0).to(device)\n",
        "            inputs_test1[-1] = inputs_test1[-1].transpose(1, 0).to(device)\n",
        "            inputs_test2[-1] = inputs_test2[-1].transpose(1, 0).to(device)\n",
        "\n",
        "        targets = torch.tensor([[1] * n_samples + [0] * n_samples] * current_batch_size).to(device).float()\n",
        "        extract1 = torch.stack(extract1)\n",
        "        extract2 = torch.stack(extract2)\n",
        "        inputs_test1 = torch.stack(inputs_test1)\n",
        "        inputs_test2 = torch.stack(inputs_test2)\n",
        "\n",
        "        res1, fingerprint1 = model(extract1, inputs_test2)\n",
        "        res2, fingerprint2 = model(extract2, inputs_test1)\n",
        "        \n",
        "\n",
        "        #print(inputs_test.shape, for_representation.shape)\n",
        "        loss1 = loss(res1, targets)\n",
        "        loss2 = loss(res2, targets)\n",
        "        loss_diff = ((fingerprint1 - fingerprint2) ** 2).mean()\n",
        "        variance = ((fingerprint1 - fingerprint1.mean(dim=0)) ** 2).mean() + ((fingerprint2 - fingerprint2.mean(dim=0)) ** 2).mean()\n",
        "        norm_loss = (fingerprint1 ** 2).mean() + (fingerprint2 ** 2).mean()\n",
        "        loss_variance = -variance\n",
        "        l = loss1 + loss_diff * 0.5 + loss_variance * 0.02 + 0.001 * norm_loss ** 2\n",
        "        if MP:\n",
        "            with amp.scale_loss(l, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            l.backward()\n",
        "        optimizer.step()\n",
        "        #if batch % 100 == 0:\n",
        "        #    losses.append(l.item())\n",
        "        if n_batch % 100 == 0:\n",
        "            mean_positive = (res1[:, :n_samples] > 0.5).float().mean().item()\n",
        "            mean_negative = (res1[:, n_samples:] > 0.5).float().mean().item()\n",
        "            print(f\"{n_batch} : {l.item()}, positive : {mean_positive}, negative : {mean_negative}, diff : {loss_diff.item()}, variance : {variance.item()}\")\n",
        "        if n_batch % 5000 == 0:\n",
        "            save_all(model, optimizer, n_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSsv_HJbUGtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_all(model, optimizer, n_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3PV0ZX2iCH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss1, loss_diff, loss_variance, norm_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhDjioOvtDuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_on_user(user):\n",
        "    model.eval()\n",
        "    favs = [tensors[i] for i in users[user]]\n",
        "    for_representation = torch.stack(favs[:512])\n",
        "    for_test = torch.stack(favs[:1])\n",
        "    for_representation = for_representation.transpose(1, 0).to(device)\n",
        "    for_test = for_test.transpose(1, 0).to(device)\n",
        "    res, fingerprint = model(for_representation.unsqueeze(0), for_test.unsqueeze(0))\n",
        "    return fingerprint.cpu()\n",
        "baseline = run_on_user(\"my_username\").data\n",
        "baseline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKg4pti079Qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = []\n",
        "for u in users:\n",
        "    l.append((((run_on_user(u) - baseline) ** 2).mean().item(), u))\n",
        "import heapq\n",
        "tmp = heapq.nlargest(16, l)\n",
        "tmp.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki5cj9z-8nkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_dict = {}\n",
        "for u in users:\n",
        "    result_dict[u] = run_on_user(u).data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dwJNBXj-aGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(result_dict, open(f\"{DATA}/users_preprocess.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}